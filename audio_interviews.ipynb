{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook file will be used to interview people and find the audio specifications needed for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.io.wavfile import read\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import time\n",
    "import pyttsx3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Audio direction\n",
    "\n",
    "For this test, participants will hear 10 sounds, each coming from one of five directions. The directions are classified as W, NW, N, NE, and E. The participant will be asked to determine where the sound came from. At the end, an accuracy score and the individual results will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_and_play_audio(direction, input_audio, freq):\n",
    "    L_hrtf_data, freq2 = sf.read('hrtf_sound_files/L_' + direction + '.wav')\n",
    "    R_hrtf_data, freq2 = sf.read('hrtf_sound_files/R_' + direction + '.wav')\n",
    "    left_audio = np.convolve(input_audio, L_hrtf_data)\n",
    "    right_audio = np.convolve(input_audio, R_hrtf_data)\n",
    "    output_audio = np.vstack((left_audio, right_audio)).T\n",
    "    sd.play(output_audio[:88200], freq)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Directions:  ['W', 'NW', 'W', 'NW', 'N', 'N', 'NW', 'W', 'NW', 'E']\n",
      "User Picked Directions:  ['W', 'NW', 'W', 'NW', 'NE', 'N', 'NW', 'W', 'NW', 'E']\n",
      "Correct:  9\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables needed for experiment\n",
    "directions = ['W', 'NW', 'N', 'NE', 'E']\n",
    "trials = 10\n",
    "input_audio_file = 'base_audio.wav'\n",
    "input_audio, freq = sf.read(input_audio_file)\n",
    "speech = pyttsx3.init()\n",
    "\n",
    "# Calibration stage - play one second of each direction; going West to East\n",
    "speech.say(\"Calibration. Get familiar with the sounds.\")\n",
    "speech.runAndWait()\n",
    "for direction in directions:\n",
    "    convolve_and_play_audio(direction, input_audio, freq)\n",
    "time.sleep(2)\n",
    "for direction in reversed(directions):\n",
    "    convolve_and_play_audio(direction, input_audio, freq)\n",
    "\n",
    "# Test: Play audio and record results\n",
    "time.sleep(3)\n",
    "speech.say(\"Test. Audio will be played. Record your results.\")\n",
    "speech.runAndWait()\n",
    "real_directions = []\n",
    "user_picked_directions = []\n",
    "correct = 0\n",
    "for trial in range(trials):\n",
    "    direction = random.choice(directions)\n",
    "    convolve_and_play_audio(direction, input_audio, freq)\n",
    "    real_directions.append(direction)\n",
    "    user_picked_directions.append(input('What direction did the sound come from? (W, NW, N, NE, E)'))\n",
    "    if real_directions[-1] == user_picked_directions[-1]:\n",
    "        correct += 1\n",
    "\n",
    "print('Real Directions: ', real_directions)\n",
    "print('User Picked Directions: ', user_picked_directions)\n",
    "print('Correct: ', correct)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
